{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Ethereum Exchange Addresses\n",
    "Each wallet on the Ethereum (ETH) blockchain is identified by a unique 42-character hexadecimal addresses (e.g. 0xDe12C3d2257fc9bB1c1A00d409f292eecD55fFaF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/ethereum-exchanges'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp = os.path.join(data_dir, 'train_data.csv')\n",
    "test_fp = os.path.join(data_dir, 'test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction data\n",
    "df_trans = pd.read_csv(\n",
    "    os.path.join(data_dir, \"token_transfers_full.csv\"), encoding=\"windows-1252\"\n",
    ")\n",
    "print(df_trans.shape)\n",
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each Token has a unique token contract address\n",
    "# Data contains 28 unique token contract address\n",
    "\n",
    "df_trans['token_address'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token details obtained from the ETH blockchain using web3.py and Infura.\n",
    "\n",
    "token_details_mapper = {\n",
    "    \"0xb64ef51c888972c908cfacf59b47c1afbc0ab8ac\": (\"StorjToken\", \"STORJ\", 8),\n",
    "    \"0xa15c7ebe1f07caf6bff097d8a589fb8ac49ae5b3\": (\"Pundi X Token\", \"NPXS\", 18),\n",
    "    \"0x1f573d6fb3f13d689ff844b4ce37794d79a7ff1c\": (\"Bancor Network Token\", \"BNT\", 18),\n",
    "    \"0xb8c77482e45f1f44de1745f52c74426c631bdd52\": (\"BNB\", \"BNB\", 18),\n",
    "    \"0xe41d2489571d322189246dafa5ebde1f4699f498\": (\"0x Protocol Token\", \"ZRX\", 18),\n",
    "    \"0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\": (\"Wrapped Ether\", \"WETH\", 18),\n",
    "    \"0x514910771af9ca656af840dff83e8264ecf986ca\": (\"ChainLink Token\", \"LINK\", 18),\n",
    "    \"0xdd974d5c2e2928dea5f71b9825b8b646686bd200\": (\"Kyber Network Crystal\", \"KNC\", 18),\n",
    "    \"0xd26114cd6ee289accf82350c8d8487fedb8a0c07\": (\"OMGToken\", \"OMG\", 18),\n",
    "    \"0x89d24a6b4ccb1b6faa2625fe562bdd9a23260359\": (\"Dai Stablecoin v1.0\", \"DAI\", 18),\n",
    "    \"0x0f5d2fb29fb7d3cfee444a200298f468908cc942\": (\"Decentraland MANA\", \"MANA\", 18),\n",
    "    \"0x8e1b448ec7adfc7fa35fc2e885678bd323176e34\": (\"Egretia\", \"EGT\", 18),\n",
    "    \"0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\": (\"USD//C\", \"USDC\", 18),\n",
    "    \"0xf629cbd94d3791c9250152bd8dfbdf380e2a3b9c\": (\"Enjin Coin\", \"ENJ\", 18),\n",
    "    \"0x9f8f72aa9304c8b593d555f12ef6589cc3a579a2\": (\"Maker\", \"MKR\", 18),\n",
    "    \"0x0d8775f648430679a709e98d2b0cb6250d2887ef\": (\"Basic Attention Token\", \"BAT\", 18),\n",
    "    \"0x8e870d67f660d95d5be530380d0ec0bd388289e1\": (\"Paxos Token\", \"PAX\", 18),\n",
    "    \"0x6f259637dcd74c767781e37bc6133cd6a68aa161\": (\"HuobiToken\", \"HT\", 18),\n",
    "    \"0x4dc3643dbc642b72c158e7f3d2ff232df61cb6ce\": (\"Amber Token\", \"AMB\", 18),\n",
    "    \"0x8971f9fd7196e5cee2c1032b50f656855af7dd26\": (\"Lambda\", \"LAMB\", 18),\n",
    "    \"0x0000000000085d4780b73119b644ae5ecd22b376\": (\"TrueUSD\", \"TUSD\", 18),\n",
    "    \"0x77fe30b2cf39245267c0a5084b66a560f1cf9e1f\": (\"Azbit\", \"AZ\", 18),\n",
    "    \"0x174bfa6600bf90c885c7c01c7031389ed1461ab9\": (\"More Gold Coin\", \"MGC\", 18),\n",
    "    \"0x8e766f57f7d16ca50b4a0b90b88f6468a09b0439\": (\"Maximine Coin\", \"MXM\", 18),\n",
    "    \"0xc12d1c73ee7dc3615ba4e37e4abfdbddfa38907e\": (\"KickToken\", \"KICK\", 8),\n",
    "    \"0xbddab785b306bcd9fb056da189615cc8ece1d823\": (\"Ebakus\", \"EBK\", 18),\n",
    "    \"0x6b175474e89094c44da98b954eedeac495271d0f\": (\"Dai Stablecoin\", \"DAI\", 18),\n",
    "    \"0x2b591e99afe9f32eaa6214f7b7629768c40eeb39\": (\"HEX\", \"HEX\", 8),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans[\"token_symbol\"] = df_trans[\"token_address\"].apply(\n",
    "    lambda x: token_details_mapper[x][1]\n",
    ")\n",
    "df_trans[\"token_decimal\"] = df_trans[\"token_address\"].apply(\n",
    "    lambda x: token_details_mapper[x][-1]\n",
    ")\n",
    "\n",
    "# Cast to float\n",
    "df_trans[\"value\"] = df_trans[\"value\"].astype(float)\n",
    "df_trans[\"token_decimal\"] = df_trans[\"token_decimal\"].astype(float)\n",
    "\n",
    "# Calculate adjusted token value\n",
    "df_trans[\"token_value\"] = df_trans.apply(\n",
    "    lambda x: x.value * (10**-x.token_decimal), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans['token_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_token_lst = [\n",
    "    \"STORJ\",\n",
    "    \"NPXS\",\n",
    "    \"BNT\",\n",
    "    \"BNB\",\n",
    "    \"ZRX\",\n",
    "    \"WETH\",\n",
    "    \"LINK\",\n",
    "    \"KNC\",\n",
    "    \"OMG\",\n",
    "    \"DAI\",\n",
    "    \"MANA\",\n",
    "    \"EGT\",\n",
    "    \"USDC\",\n",
    "    \"ENJ\",\n",
    "    \"MKR\",\n",
    "    \"BAT\",\n",
    "    \"PAX\",\n",
    "    \"HT\",\n",
    "    \"AMB\",\n",
    "    \"LAMB\",\n",
    "    \"TUSD\",\n",
    "    \"AZ\",\n",
    "    \"MGC\",\n",
    "    \"MXM\",\n",
    "    \"KICK\",\n",
    "    \"EBK\",\n",
    "    \"HEX\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = df_trans.loc[\n",
    "    (df_trans[\"token_symbol\"].isin(top_n_token_lst))\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(df_trans.shape)\n",
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Generate Address-level features\n",
    "df_trans_out_agg = (\n",
    "    df_trans.groupby([\"to_address\", \"token_symbol\"])\n",
    "    .agg(\n",
    "        f_out_total_token_value=(\"token_value\", \"sum\"),\n",
    "        f_out_mean_token_value=(\"token_value\", \"mean\"),\n",
    "        f_out_median_token_value=(\"token_value\", \"median\"),\n",
    "        f_out_min_token_value=(\"token_value\", \"min\"),\n",
    "        f_out_max_token_value=(\"token_value\", \"max\"),\n",
    "        # Number of addresses trades were made from\n",
    "        f_out_address_count=(\"from_address\", \"count\"),\n",
    "        f_out_address_unique_count=(\"from_address\", \"nunique\"),\n",
    "        # Total Duration of trade\n",
    "        f_out_block_number_diff=(\"block_number\", lambda x: x.max() - x.min()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_trans_out_agg = df_trans_out_agg.pivot_table(\n",
    "    index=\"to_address\",\n",
    "    columns=\"token_symbol\",\n",
    "    values=[\n",
    "        \"f_out_total_token_value\",\n",
    "        \"f_out_mean_token_value\",\n",
    "        \"f_out_median_token_value\",\n",
    "        \"f_out_min_token_value\",\n",
    "        \"f_out_max_token_value\",\n",
    "        \"f_out_address_count\",\n",
    "        \"f_out_address_unique_count\",\n",
    "        \"f_out_block_number_diff\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "df_trans_out_agg.columns = [f'{stat}_{token}' for stat, token in df_trans_out_agg.columns]\n",
    "df_trans_out_agg = df_trans_out_agg.reset_index()\n",
    "df_trans_out_agg.rename(columns={'to_address': 'address'}, inplace=True)\n",
    "df_trans_out_agg.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_trans_in_agg = (\n",
    "    df_trans.groupby([\"from_address\", \"token_symbol\"])\n",
    "    .agg(\n",
    "        f_in_total_token_value=(\"token_value\", \"sum\"),\n",
    "        f_in_mean_token_value=(\"token_value\", \"mean\"),\n",
    "        f_in_median_token_value=(\"token_value\", \"median\"),\n",
    "        f_in_mf_in_token_value=(\"token_value\", \"min\"),\n",
    "        f_in_max_token_value=(\"token_value\", \"max\"),\n",
    "        f_in_address_count=(\"to_address\", \"count\"),\n",
    "        f_in_address_unique_count=(\"to_address\", \"nunique\"),\n",
    "        f_in_block_number_diff=(\"block_number\", lambda x: x.max() - x.min()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "df_trans_in_agg = df_trans_in_agg.pivot_table(\n",
    "    index=\"from_address\",\n",
    "    columns=\"token_symbol\",\n",
    "    values=[\n",
    "        \"f_in_total_token_value\",\n",
    "        \"f_in_mean_token_value\",\n",
    "        \"f_in_median_token_value\",\n",
    "        \"f_in_mf_in_token_value\",\n",
    "        \"f_in_max_token_value\",\n",
    "        \"f_in_address_count\",\n",
    "        \"f_in_address_unique_count\",\n",
    "        \"f_in_block_number_diff\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_trans_in_agg.columns = [f'{stat}_{token}' for stat, token in df_trans_in_agg.columns]\n",
    "df_trans_in_agg = df_trans_in_agg.reset_index()\n",
    "df_trans_in_agg.rename(columns={'from_address': 'address'}, inplace=True)\n",
    "df_trans_in_agg.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_node_lst = df_ex_train['address'].tolist()\n",
    "df_train = pd.read_csv(train_fp)\n",
    "df_train = pd.merge(df_train, df_trans_in_agg, how='left', on=['address'])\n",
    "df_train = pd.merge(df_train, df_trans_out_agg, how='left', on=['address'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_node_lst = df_ex_test['address'].tolist()\n",
    "df_test = pd.read_csv(test_fp)\n",
    "df_test = pd.merge(df_test, df_trans_in_agg, how='left', on=['address'])\n",
    "df_test = pd.merge(df_test, df_trans_out_agg, how='left', on=['address'])\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = [x for x in df_train.columns if bool(re.search(\"f_\", x))]\n",
    "drop_cols = []\n",
    "f_cols = list(set(f_cols) - set(drop_cols))\n",
    "print(f_cols)\n",
    "\n",
    "lbl_col = \"lbl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_f_cols = list(set(df_train.columns).intersection(f_cols))\n",
    "x_train = df_train[final_f_cols]\n",
    "y_train = df_train[lbl_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test[final_f_cols]\n",
    "y_test = df_test[lbl_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns_match = (x_test.columns == x_train.columns).all()\n",
    "print(f\"all_columns_match: {all_columns_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=random_seed\n",
    ")\n",
    "print(f\"train: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"val: {x_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on feature engineering, not on model fine-tuning\n",
    "model = CatBoostClassifier(\n",
    "    learning_rate=0.05,\n",
    "    iterations=2000,        # Equivalent to n_estimators\n",
    "    depth=8,                # Equivalent to max_depth\n",
    "    subsample=0.8,\n",
    "    rsm=0.8,                # Equivalent to feature_fraction (RSM = Random Subspace Method)\n",
    "    bagging_temperature=1.0, # Similar to bagging_fraction but with a different mechanism\n",
    "    random_seed=random_seed,\n",
    "    verbose=0,              # Silence the training output\n",
    "#     early_stopping_rounds=50 # Enable early stopping\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    eval_set=(x_val, y_val),  # Validation set for early stopping\n",
    "    use_best_model=True,      # Saves the best model during training\n",
    "    verbose=True             # Suppress logs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(x_test)\n",
    "df_result = pd.DataFrame(\n",
    "    {\n",
    "        \"address\": df_test[\"address\"].tolist(),\n",
    "        \"pred_pos\": y_pred_proba[:, 1],\n",
    "        \"pred_neg\": y_pred_proba[:, 0],\n",
    "        \"lbl\": y_test\n",
    "    }\n",
    ")\n",
    "\n",
    "df_result['pred'] = 0\n",
    "df_result.loc[(df_result['pred_pos']>df_result['pred_neg']), 'pred'] = 1\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = precision_score(df_result['lbl'], df_result['pred'])\n",
    "recall = recall_score(df_result['lbl'], df_result['pred'])\n",
    "f1 = f1_score(df_result['lbl'], df_result['pred'])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: \n",
    "- Threshold based on predicted probability\n",
    "- Reduce sparse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
